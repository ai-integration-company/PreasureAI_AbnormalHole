{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:37.908382Z",
     "iopub.status.busy": "2025-03-08T21:54:37.908015Z",
     "iopub.status.idle": "2025-03-08T21:54:45.175586Z",
     "shell.execute_reply": "2025-03-08T21:54:45.174434Z",
     "shell.execute_reply.started": "2025-03-08T21:54:37.908345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "from pta_learn.tpmr import TPMR\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.178004Z",
     "iopub.status.busy": "2025-03-08T21:54:45.177315Z",
     "iopub.status.idle": "2025-03-08T21:54:45.18305Z",
     "shell.execute_reply": "2025-03-08T21:54:45.181941Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.177969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_markup(markup_path):\n",
    "    df = pd.read_csv(markup_path, sep=';')\n",
    "    df['recovery'] = df['recovery'].apply(ast.literal_eval)\n",
    "    df['drop'] = df['drop'].apply(ast.literal_eval)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.185253Z",
     "iopub.status.busy": "2025-03-08T21:54:45.184857Z",
     "iopub.status.idle": "2025-03-08T21:54:45.206459Z",
     "shell.execute_reply": "2025-03-08T21:54:45.205101Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.185214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_segment(df, grid_timestep=0.01, smoothing_time_window=5, interp_method='time'):\n",
    "    seg = df.copy()\n",
    "    seg.set_index('Time', inplace=True)\n",
    "    stt, endt = np.floor(seg.index.min()), np.ceil(seg.index.max())\n",
    "    uniform_times = np.arange(stt, endt + 1, grid_timestep)\n",
    "    \n",
    "    seg.index = pd.to_timedelta(seg.index, unit='h')\n",
    "    new_times = pd.to_timedelta(uniform_times, unit='h')\n",
    "    union_idx = seg.index.union(new_times)\n",
    "    \n",
    "    # Interpolate and fill remaining NaNs\n",
    "    seg_interp = seg.reindex(union_idx).interpolate(interp_method).ffill().bfill()\n",
    "    \n",
    "    index_window_size = int(float(smoothing_time_window) / float(grid_timestep))\n",
    "    index_window_size = int(index_window_size)  # Ensure it's an integer\n",
    "    \n",
    "    seg_uniform = seg_interp.reindex(new_times)\n",
    "    \n",
    "    # Apply rolling mean and fill NaNs resulting from the window\n",
    "    seg_uniform = seg_uniform.rolling(window=index_window_size, center=True, min_periods=1).mean()\n",
    "    \n",
    "    # Handle any remaining edge NaNs (though min_periods=1 should prevent them)\n",
    "    seg_uniform = seg_uniform.ffill().bfill()\n",
    "    \n",
    "    seg_uniform.index = seg_uniform.index.total_seconds() / 3600\n",
    "    seg_uniform.reset_index(inplace=True)\n",
    "    seg_uniform.columns = ['Time', 'Pressure']\n",
    "    seg_uniform['Timestamp'] = pd.to_timedelta(seg_uniform['Time'], unit='h')\n",
    "    return seg_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.207873Z",
     "iopub.status.busy": "2025-03-08T21:54:45.207543Z",
     "iopub.status.idle": "2025-03-08T21:54:45.232089Z",
     "shell.execute_reply": "2025-03-08T21:54:45.230891Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.207845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_series(series_path):\n",
    "    df = pd.read_csv(series_path, delimiter='\\t', header=None, names=['Time', 'Pressure'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.234133Z",
     "iopub.status.busy": "2025-03-08T21:54:45.233743Z",
     "iopub.status.idle": "2025-03-08T21:54:45.252893Z",
     "shell.execute_reply": "2025-03-08T21:54:45.251715Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.234093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_series_by_gap(df,gap):\n",
    "    segments = []\n",
    "    start_idx = 0\n",
    "    ts = df['Time'].values\n",
    "    for i in range(1, len(ts)):\n",
    "        if (ts[i] - ts[i-1]) > gap:\n",
    "            segments.append(df.iloc[start_idx:i].copy())\n",
    "            start_idx = i\n",
    "    if start_idx < len(ts):\n",
    "        segments.append(df.iloc[start_idx:].copy())\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.254734Z",
     "iopub.status.busy": "2025-03-08T21:54:45.25437Z",
     "iopub.status.idle": "2025-03-08T21:54:45.273846Z",
     "shell.execute_reply": "2025-03-08T21:54:45.272807Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.254697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_recovery_intervals(df_bhp, p = 1, int_len_treshhold = 70):\n",
    "    df = df_bhp.copy()\n",
    "    df['Pressure'] = -df['Pressure'].values + np.max(df['Pressure'].values)\n",
    "    shutin_bp_all, shutin_bp_interval, shutin_transient_all, shutin_transient_interval = TPMR(df, p, int_len_treshhold)\n",
    "    \n",
    "    if shutin_transient_interval.empty:\n",
    "        shutin_transient_interval = pd.DataFrame(columns = ['start','end'])\n",
    "    else:\n",
    "        shutin_transient_interval = shutin_transient_interval[['start/hr', 'end/hr']]\n",
    "        shutin_transient_interval.columns = ['start','end']\n",
    "    return shutin_transient_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.277064Z",
     "iopub.status.busy": "2025-03-08T21:54:45.276715Z",
     "iopub.status.idle": "2025-03-08T21:54:45.297095Z",
     "shell.execute_reply": "2025-03-08T21:54:45.295905Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.277034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_drop_intervals(df_bhp, p = 1, int_len_treshhold = 70):\n",
    "    shutin_bp_all, shutin_bp_interval, shutin_transient_all, shutin_transient_interval = TPMR(df_bhp, p, int_len_treshhold)\n",
    "    if shutin_transient_interval.empty:\n",
    "        shutin_transient_interval = pd.DataFrame(columns = ['start','end'])\n",
    "    else:\n",
    "        shutin_transient_interval = shutin_transient_interval[['start/hr', 'end/hr']]\n",
    "        shutin_transient_interval.columns = ['start','end']\n",
    "    return shutin_transient_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.299896Z",
     "iopub.status.busy": "2025-03-08T21:54:45.299424Z",
     "iopub.status.idle": "2025-03-08T21:54:45.318148Z",
     "shell.execute_reply": "2025-03-08T21:54:45.316918Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.299852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit_ln_curve(df):\n",
    "    df = df[df['Time'] > 0].copy()\n",
    "    \n",
    "    def objective(epsilon_shift):\n",
    "        df['lnTime'] = np.log(df['Time'] + epsilon_shift)\n",
    "        \n",
    "        X = np.vstack([df['lnTime'], np.ones(len(df))]).T\n",
    "        y = df['Pressure'].values\n",
    "        \n",
    "        coeff, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        q, b = coeff\n",
    "        \n",
    "        y_pred = q * df['lnTime'] + b\n",
    "        \n",
    "        return mean_squared_error(y, y_pred)\n",
    "    \n",
    "    result = minimize_scalar(objective, bounds=(-min(df['Time']), 1), method='bounded')\n",
    "    best_epsilon_shift = result.x\n",
    "    \n",
    "    df['lnTime'] = np.log(df['Time'] + best_epsilon_shift)\n",
    "    X = np.vstack([df['lnTime'], np.ones(len(df))]).T\n",
    "    y = df['Pressure'].values\n",
    "    coeff, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    q, b = coeff\n",
    "    y_pred = q * df['lnTime'] + b\n",
    "    \n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    return {'q': q, 'b': b, 'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'Epsilon Shift': best_epsilon_shift}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.31994Z",
     "iopub.status.busy": "2025-03-08T21:54:45.319523Z",
     "iopub.status.idle": "2025-03-08T21:54:45.341889Z",
     "shell.execute_reply": "2025-03-08T21:54:45.340677Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.319899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def overlap_ratio(interval1, interval2):\n",
    "    start1, end1 = interval1\n",
    "    start2, end2 = interval2\n",
    "    intersection = max(0, min(end1, end2) - max(start1, start2))\n",
    "    union = max(end1, end2) - min(start1, start2)\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.343321Z",
     "iopub.status.busy": "2025-03-08T21:54:45.342952Z",
     "iopub.status.idle": "2025-03-08T21:54:45.360367Z",
     "shell.execute_reply": "2025-03-08T21:54:45.359159Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.34328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def max_overlap_from_df2(row, df2):\n",
    "    start1, end1 = row['start'], row['end']\n",
    "    overlaps = df2.apply(lambda x: overlap_ratio((start1, end1), (x['start'], x['end'])), axis=1)\n",
    "    return overlaps.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.361949Z",
     "iopub.status.busy": "2025-03-08T21:54:45.36159Z",
     "iopub.status.idle": "2025-03-08T21:54:45.381443Z",
     "shell.execute_reply": "2025-03-08T21:54:45.380067Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.361908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def filter_intervals(int_pred, int_true,overlap_threshold = 0.5):\n",
    "    # Вычисляем для каждого интервала из df1 максимальное перекрытие с интервалами из df2\n",
    "    int_pred['max_overlap'] = int_pred.apply(lambda row: max_overlap_from_df2(row, int_true), axis=1)\n",
    "    # Фильтруем интервалы, максимальное перекрытие которых меньше порога\n",
    "    filtered_df1 = int_pred[int_pred['max_overlap'] < overlap_threshold]\n",
    "    return filtered_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.383014Z",
     "iopub.status.busy": "2025-03-08T21:54:45.382687Z",
     "iopub.status.idle": "2025-03-08T21:54:45.405833Z",
     "shell.execute_reply": "2025-03-08T21:54:45.404664Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.382983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_tsfresh_features(df):\n",
    "    # For a single time series, add an id column (all rows belong to the same series)\n",
    "    df['id'] = 1  \n",
    "    \n",
    "    # Extract features; the result is a DataFrame with one row per id\n",
    "    features_df = extract_features(df, \n",
    "                                   column_id='id',\n",
    "                                   column_sort='Time',\n",
    "                                   column_value='Pressure',\n",
    "                                   default_fc_parameters = MinimalFCParameters(),\n",
    "                                   n_jobs = 1)\n",
    "    \n",
    "    # Convert the features of our single time series to a dict\n",
    "    features_dict = features_df.iloc[0].to_dict()\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.407262Z",
     "iopub.status.busy": "2025-03-08T21:54:45.406945Z",
     "iopub.status.idle": "2025-03-08T21:54:45.43095Z",
     "shell.execute_reply": "2025-03-08T21:54:45.429695Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.407236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_train_set(df_markup, dataset_path):\n",
    "    dataset = []\n",
    "    for index, row in df_markup.iterrows():\n",
    "        print(f\"№{index}/{len(df_markup)}: {row['file']}\")\n",
    "        series_path = os.path.join(dataset_path, row['file'])\n",
    "        if not os.path.exists(series_path):\n",
    "            print(f\"path {series_path} does not exist\")\n",
    "            continue\n",
    "            \n",
    "        series = load_series(series_path)\n",
    "        segments = split_series_by_gap(series, 50)\n",
    "        \n",
    "        recovery_ints = pd.DataFrame(row['recovery'], columns=['start', 'end'])\n",
    "        drop_ints = pd.DataFrame(row['drop'], columns=['start', 'end'])\n",
    "        \n",
    "        recovery_ints_pred = []\n",
    "        drop_ints_pred = []\n",
    "        for seg in segments:\n",
    "            if len(seg) < 20:\n",
    "                continue\n",
    "            proc_seg = preprocess_segment(seg, smoothing_time_window = 7)\n",
    "            recovery_ints_pred.append(get_recovery_intervals(proc_seg))\n",
    "            drop_ints_pred.append(get_drop_intervals(proc_seg))\n",
    "\n",
    "        recovery_ints_pred = pd.concat(recovery_ints_pred)\n",
    "        drop_ints_pred = pd.concat(drop_ints_pred)\n",
    "        \n",
    "        recovery_ints['type'] = 'recovery'\n",
    "        drop_ints['type'] = 'drop'\n",
    "        recovery_ints_pred['type'] = 'recovery'\n",
    "        drop_ints_pred['type'] = 'drop'\n",
    "        \n",
    "        if recovery_ints.empty:\n",
    "            filtered_recovery = recovery_ints.copy()\n",
    "        else:\n",
    "            filtered_recovery = filter_intervals(recovery_ints_pred, recovery_ints)\n",
    "\n",
    "        if drop_ints.empty:\n",
    "            filtered_drop = drop_ints.copy()\n",
    "        else:\n",
    "            filtered_drop = filter_intervals(drop_ints_pred, drop_ints)\n",
    "            \n",
    "        true_ints = pd.concat([recovery_ints, drop_ints])\n",
    "        filtered_ints = pd.concat([filtered_recovery, filtered_drop])\n",
    "        true_ints['class'] = 1\n",
    "        filtered_ints['class'] = 0\n",
    "        all_ints = pd.concat([true_ints, filtered_ints])\n",
    "\n",
    "        print(f\"{len(recovery_ints)} true recovery intervals\")\n",
    "        print(f\"{len(drop_ints)} true drop intervals\")\n",
    "        print(f\"{len(recovery_ints_pred)} predicted recovery intervals\")\n",
    "        print(f\"{len(drop_ints_pred)} predicted drop intervals\")\n",
    "        print(f\"{len(filtered_recovery)} filtered recovery intervals\")\n",
    "        print(f\"{len(filtered_drop)} filtered drop intervals\")\n",
    "        print(\"|-------------------------------------------|\")\n",
    "        for _, interval in all_ints.iterrows():\n",
    "            segment = series[(series['Time'] >= interval['start']) & (series['Time'] <= interval['end'])]\n",
    "            if len(segment) < 20:\n",
    "                continue\n",
    "            seg = segment.copy()\n",
    "            seg['Time'] = seg['Time'].values - np.min(seg['Time'].values)\n",
    "            output = fit_ln_curve(seg)\n",
    "            output['file'] = row['file']\n",
    "            output['interval_start'] = interval['start']\n",
    "            output['interval_end'] = interval['end']\n",
    "            output['type'] = interval['type']\n",
    "            output['class'] = interval['class']\n",
    "\n",
    "            # features\n",
    "            output['duration'] = interval['end'] - interval['start']\n",
    "            output['len'] = len(seg)\n",
    "            output['type_binary'] = 1 if interval['type'] == 'recovery' else 0\n",
    "            output['amplitude'] = seg['Pressure'].max() - seg['Pressure'].min()\n",
    "\n",
    "            tsfresh_feat = compute_tsfresh_features(seg)\n",
    "            output.update(tsfresh_feat)\n",
    "            dataset.append(output)\n",
    "            \n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T22:18:28.037517Z",
     "iopub.status.busy": "2025-03-08T22:18:28.037118Z",
     "iopub.status.idle": "2025-03-08T22:18:28.045171Z",
     "shell.execute_reply": "2025-03-08T22:18:28.043463Z",
     "shell.execute_reply.started": "2025-03-08T22:18:28.037487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    X = data.drop(columns=['class'])\n",
    "    y = data['class']\n",
    "    \n",
    "    # Optional\n",
    "    #scaler = StandardScaler()\n",
    "    #X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = X\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Model Evaluation:\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.479113Z",
     "iopub.status.busy": "2025-03-08T21:54:45.478737Z",
     "iopub.status.idle": "2025-03-08T21:54:45.501056Z",
     "shell.execute_reply": "2025-03-08T21:54:45.499694Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.479076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = r'./dataset'\n",
    "markup_csv_path = r'./markup.csv'\n",
    "train_path = r'./train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:54:45.502472Z",
     "iopub.status.busy": "2025-03-08T21:54:45.502117Z",
     "iopub.status.idle": "2025-03-08T21:54:45.54563Z",
     "shell.execute_reply": "2025-03-08T21:54:45.544523Z",
     "shell.execute_reply.started": "2025-03-08T21:54:45.502434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "markup = load_markup(markup_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(train_path):\n",
    "    print(\"load existing training set\")\n",
    "    df_train = pd.read_csv(train_path)\n",
    "else:\n",
    "    df_train = build_train_set(markup, dataset_path)\n",
    "    df_train.to_csv(train_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T21:59:56.606236Z",
     "iopub.status.busy": "2025-03-08T21:59:56.605835Z",
     "iopub.status.idle": "2025-03-08T21:59:56.611677Z",
     "shell.execute_reply": "2025-03-08T21:59:56.610663Z",
     "shell.execute_reply.started": "2025-03-08T21:59:56.606195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_feats = df_train.drop(['file','interval_start','interval_end','type'], axis = 1)\n",
    "model = train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6774421,
     "sourceId": 10959030,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
